# 操作系统

> 面向进程和线程学习操作系统。

# 目录

| Chapter 1 | Chapter 2 | Chapter 3| Chapter 4 | Chapter 5| Chapter 6 |
| :---------: | :---------: | :---------: | :---------: | :---------: | :---------: |
|[进程线程模型](#进程线程模型)|[进程间通信](#进程间通信)|[线程间通信](#线程间通信)|[同步互斥机制](#同步互斥机制)|[网络I/O模型](#网络I/O模型)| [死锁](#死锁) |

---

# 内容

### 进程线程模型

线程和进程的概念已经在操作系统书中被翻来覆去讲了很多遍。很多概念虽然都是套话，但没能理解透其中深意会导致很多内容理解不清晰。对于进程和线程的理解和把握可以说基本奠定了对系统的认知和把控能力。其核心意义绝不仅仅是 “**线程是调度的基本单位，进程是资源分配的基本单位**” 这么简单。

**进程之间私有和共享的资源**

- 私有：地址空间、堆、全局变量、栈、寄存器
- 共享：代码段，公共数据，进程目录，进程 ID

**线程之间私有和共享的资源**

- 私有：线程栈，寄存器，程序计数器
- 共享：堆，地址空间，全局变量，静态变量

**多线程**

我们这里讨论的是用户态的多线程模型，同一个进程内部有多个线程，所有的线程共享同一个进程的内存空间，进程中定义的全局变量会被所有的线程共享，比如有全局变量 `int i = 10`，这一进程中所有并发运行的线程都可以读取和修改这个i的值，而多个线程被CPU调度的顺序又是不可控的，所以对临界资源的访问尤其需要注意安全。我们必须知道，做一次简单的 `i = i + 1` 在计算机中并不是**原子操作**，涉及内存取数，计算和写入内存几个环节，而线程的切换有可能发生在上述任何一个环节中间，所以不同的操作顺序很有可能带来意想不到的结果。

但是，虽然线程在安全性方面会引入许多新挑战，但是线程带来的好处也是有目共睹的。首先，原先顺序执行的程序（暂时不考虑多进程）可以被拆分成几个独立的逻辑流，这些逻辑流可以独立完成一些任务（最好这些任务是不相关的）。比如QQ可以一个线程处理聊天一个线程处理上传文件，两个线程互不干涉，在用户看来是同步在执行两个任务，试想如果线性完成这个任务的话，在数据传输完成之前用户聊天被一直阻塞会是多么尴尬的情况。

对于线程，我认为弄清以下两点非常重要：

- **线程之间有无先后访问顺序（线程依赖关系）**

- **多个线程共享访问同一变量（同步互斥问题）**

另外，我们通常只会去说同一进程的多个线程共享进程的资源，但是每个线程特有的部分却很少提及，除了标识线程的tid，每个线程还有自己独立的栈空间，线程彼此之间是无法访问其他线程栈上内容的。而作为处理机调度的最小单位，线程调度只需要保存线程栈、寄存器数据和PC即可，相比进程切换开销要小很多。

线程相关接口不少，主要需要了解各个参数意义和返回值意义。

1. 线程创建和结束

    - 背景知识：

        在一个文件内的多个函数通常都是按照main函数中出现的顺序来执行，但是在分时系统下，我们可以让每个函数都作为一个逻辑流并发执行，最简单的方式就是采用多线程策略。在main函数中调用多线程接口创建线程，每个线程对应特定的函数（操作），这样就可以不按照main函数中各个函数出现的顺序来执行，避免了忙等的情况。线程基本操作的接口如下。

    - 相关接口：

        - 创建线程：`int pthread_create(pthread_t *pthread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *agr);`

            创建一个新线程，pthread和start_routine不可或缺，分别用于标识线程和执行体入口，其他可以填NULL。

            - **pthread：用来返回线程的tid，*pthread值即为tid，类型 `pthread_t == unsigned long int`。**
        
            - attr：指向线程属性结构体的指针，用于改变所创线程的属性，填NULL使用默认值。
        
            - **start_routine：线程执行函数的首地址，传入函数指针。**
        
            - arg：通过地址传递来传递函数参数，这里是无符号类型指针，可以传任意类型变量的地址，在被传入函数中先强制类型转换成所需类型即可。

        - 获得线程ID：`pthread_t pthread_self();`

            调用时，会打印线程ID。

        - 等待线程结束：`int pthread_join(pthread_t tid, void** retval);`

            主线程调用，等待子线程退出并回收其资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join的线程会被阻塞。

            - tid：创建线程时通过指针得到tid值。

            - retval：指向返回值的指针。

        - 结束线程：`pthread_exit(void *retval);`

            子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得。

            - retval：同上。

        - 分离线程：`int pthread_detach(pthread_t tid);`

            主线程、子线程均可调用。主线程中pthread_detach(tid)，子线程中pthread_detach(pthread_self())，调用后和主线程分离，子线程结束时自己立即回收资源。

            - tid：同上。

2. 线程属性值修改

    - 背景知识：

        线程属性对象类型为pthread_attr_t，结构体定义如下：
        ```cpp
        typedef struct{
            int etachstate;    		// 线程分离的状态
            int schedpolicy;    	// 线程调度策略
            struct sched_param schedparam;    // 线程的调度参数
            int inheritsched;    	// 线程的继承性
            int scope;    			// 线程的作用域
            // 以下为线程栈的设置
            size_t guardsize;    	// 线程栈末尾警戒缓冲大小
            int stackaddr_set;    	// 线程的栈设置
            void *stackaddr;  		// 线程栈的位置
            size_t stacksize;    	// 线程栈大小
        }pthread_arrt_t;
        ```

    - 相关接口：

        对上述结构体中各参数大多有：pthread_attr_get()和pthread_attr_set()系统调用函数来设置和获取。这里不一一罗列。

3. 线程同步

    - [详见同步互斥专题](#同步互斥机制)

**多进程**

每一个进程是资源分配的基本单位。进程结构由以下几个部分组成：代码段、堆栈段、数据段。代码段是静态的二进制代码，多个程序可以共享。实际上在父进程创建子进程之后，父、子进程除了pid外，几乎所有的部分几乎一样，子进程创建时拷贝父进程PCB中大部分内容，而PCB的内容实际上是各种数据、代码的地址或索引表地址，所以复制了PCB中这些指针实际就等于获取了全部父进程可访问数据。所以简单来说，创建新进程需要复制整个PCB，之后操作系统将PCB添加到进程核心堆栈底部，这样就可以被操作系统感知和调度了。

**父、子进程共享全部数据，但并不是说他们就是对同一块数据进行操作，子进程在读写数据时会通过写时复制机制将公共的数据重新拷贝一份，之后在拷贝出的数据上进行操作。如果子进程想要运行自己的代码段，还可以通过调用execv()函数重新加载新的代码段，之后就和父进程独立开了。** 我们在shell中执行程序就是通过shell进程先fork()一个子进程再通过execv()重新加载新的代码段的过程。

1. 进程创建与结束

- 背景知识：

    进程有两种创建方式，一种是操作系统创建的一种是父进程创建的。从计算机启动到终端执行程序的过程为：0号进程 -> 1号内核进程 -> 1号用户进程(init进程) -> getty进程 -> shell进程 -> 命令行执行进程。所以我们在命令行中通过 ./program执行可执行文件时，所有创建的进程都是shell进程的子进程，这也就是为什么shell一关闭，在shell中执行的进程都自动被关闭的原因。从shell进程到创建其他子进程需要通过以下接口。

- 相关接口：
  - 创建进程：`pid_t fork(void);`

      返回值：出错返回-1；父进程中返回pid > 0；子进程中pid == 0

  - 结束进程：`void exit(int status);`

      - status是退出状态，保存在全局变量中S?，通常0表示正常退出。

  - 获得PID：`pid_t getpid(void);`

      返回调用者pid。

  - 获得父进程PID：`pid_t getppid(void);`

      返回父进程pid。

  - 其他补充：

      - 正常退出方式：exit()、_exit()、return（在main中）。
        
          exit()和\_exit()区别：exit()是对\_exit()的封装，都会终止进程并做相关收尾工作，最主要的区别是\_exit()函数关闭全部描述符和清理函数后不会刷新流，但是exit()会在调用\_exit()函数前**刷新数据流**。

          return和exit()区别：exit()是函数，但有参数，执行完之后控制权交给系统。return若是在调用函数中，执行完之后控制权交给调用进程，若是在main函数中，控制权交给系统。

      - 异常退出方式：abort()、终止信号。

2. 僵尸进程、孤儿进程

- 背景知识：

    父进程在调用fork接口之后和子进程已经可以独立开，之后父进程和子进程就以未知的顺序向下执行（异步过程）。所以父进程和子进程都有可能先执行完。当父进程先结束，子进程此时就会变成**孤儿进程**，不过这种情况问题不大，孤儿进程会自动向上被init进程收养，init进程完成对状态收集工作。而且这种过继的方式也是守护进程能够实现的因素。如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，那么子进程描述符就会一直保存在系统中，这种进程称为**僵尸进程**。

- 相关接口：

   -  回收进程（1）：pid_t wait(int *status);
   
        一旦调用wait()，就会立即阻塞自己，wait()自动分析某个子进程是否已经退出，如果找到僵尸进程就会负责收集和销毁，如果没有找到就一直阻塞在这里。

        - status：指向子进程结束状态值。

    - 回收进程（2）：pid_t waitpid(pid_t pid, int *status, int options);

         返回值：返回pid：返回收集的子进程id。返回-1：出错。返回0：没有被手机的子进程。

        - pid：子进程识别码，控制等待哪些子进程。
            1. pid < -1，等待进程组识别码为pid绝对值的任何进程。

            2. pid = -1，等待任何子进程。

            3. pid = 0，等待进程组识别码与目前进程相同的任何子进程。

            4. pid > 0，等待任何子进程识别码为pid的子进程。

        - status：指向返回码的指针。

        - options：选项决定父进程调用waitpid后的状态。

            1. options = WNOHANG，即使没有子进程退出也会立即返回。

            2. options = WUNYRACED，子进程进入暂停马上返回，但结束状态不予理会。

3. 守护进程

 - 背景知识：

    守护进程是脱离终端并在后台运行的进程，执行过程中信息不会显示在终端上并且也不会被终端发出的信号打断。

 - 操作步骤：

    - 创建子进程，父进程退出：fork() + if(pid > 0){exit(0);}，使子进程称为孤儿进程被init进程收养。

    - 在子进程中创建新会话：setsid()。

    - 改变当前目录结构为根：chdir("/")。

    - 重设文件掩码：umask(0)。

    - 关闭文件描述符：for(int i = 0; i < 65535; ++i){close(i);}。

4. Linux进程控制

- 进程地址空间（地址空间）

    虚拟存储器为每个进程提供了独占系统地址空间的假象。尽管每个进程地址空间内容不尽相同，但是他们的都有相似的结构。X86 Linux进程的地址空间底部是保留给用户程序的，包括文本、数据、堆、栈等，其中文本区和数据区是通过存储器映射方式将磁盘中可执行文件的相应段映射至虚拟存储器地址空间中。有一些"敏感"的地址需要注意下，对于32位进程来说，代码段从0x08048000开始。从0xC0000000开始到0xFFFFFFFF是内核地址空间，通常情况下代码运行在用户态（使用0x00000000 ~ 0xC00000000的用户地址空间），当发生系统调用、进程切换等操作时CPU控制寄存器设置模式位，进入内和模式，在该状态（超级用户模式）下进程可以访问全部存储器位置和执行全部指令。也就说32位进程的地址空间都是4G，但用户态下只能访问低3G的地址空间，若要访问3G ~ 4G的地址空间则只有进入内核态才行。

- 进程控制块（处理机）

    进程的调度实际就是内核选择相应的进程控制块，被选择的进程控制块中包含了一个进程基本的信息。

- 上下文切换

    内核管理所有进程控制块，而进程控制块记录了进程全部状态信息。每一次进程调度就是一次上下文切换，所谓的上下文本质上就是当前运行状态，主要包括通用寄存器、浮点寄存器、状态寄存器、程序计数器、用户栈和内核数据结构（页表、进程表、文件表）等。进程执行时刻，内核可以决定抢占当前进程并开始新的进程，这个过程由内核调度器完成，当调度器选择了某个进程时称为该进程被调度，该过程通过上下文切换来改变当前状态。一次完整的上下文切换通常是进程原先运行于用户态，之后因系统调用或时间片到切换到内核态执行内核指令，完成上下文切换后回到用户态，此时已经切换到进程B。

**多进程与多线程间的对比、优劣与选择**

对比

| 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| 数据共享、同步 | 数据共享复杂，需要用 IPC；数据是分开的，同步简单             | 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU 利用率低                           | 占用内存少，切换简单，CPU 利用率高                           | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度很快                                 | 线程占优 |
| 编程、调试     | 编程简单，调试简单                                           | 编程复杂，调试复杂                                           | 进程占优 |
| 可靠性         | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉                               | 进程占优 |
| 分布式         | 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布式                                             | 进程占优 |

优劣

| 优劣 | 多进程                                   | 多线程                                   |
| ---- | ---------------------------------------- | ---------------------------------------- |
| 优点 | 编程、调试简单，可靠性较高               | 创建、销毁、切换速度快，内存、资源占用小 |
| 缺点 | 创建、销毁、切换速度慢，内存、资源占用大 | 编程、调试复杂，可靠性较差               |

选择

- 需要频繁创建销毁的优先用线程
- 需要进行大量计算的优先使用线程
- 强相关的处理用线程，弱相关的处理用进程
- 可能要扩展到多机分布的用进程，多核分布的用线程
- 都满足需求的情况下，用你最熟悉、最拿手的方式

**线程、进程比较**

关于进程和线程的区别这里就不一一罗列了，主要对比下线程和进程操作中主要的接口。

- fork()和pthread_create()

    负责创建。调用fork()后返回两次，一次标识主进程一次标识子进程；调用pthread_create()后得到一个可以独立执行的线程。

- wait()和pthread_join()

    负责回收。调用wait()后父进程阻塞；调用pthread_join()后主线程阻塞。

- exit()和pthread_exit()

    负责退出。调用exit()后调用进程退出，控制权交给系统；调用pthread_exit()后线程退出，控制权交给主线程。

---

### 进程间通信

- **有名管道（named pipe/FIFO）**：一种半双工的通信方式，它允许无亲缘关系进程间的通信
  - 优点：可以实现任意关系的进程间的通信
  - 缺点：
    1. 长期存于系统中，使用不当容易出错
    2. 缓冲区有限
- **无名管道（PIPE）**：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
  - 优点：简单方便
  - 缺点：
    1. 局限于单向通信
    2. 只能创建在它的进程以及其有亲缘关系的进程之间
    3. 缓冲区有限
- ~~**管道的通信方式是效率低的，因此不适合进程间频繁地交换数据。**~~
- **消息队列（Message Queue）**：是消息的链表，存放在内核中并由消息队列标识符标识
  - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
  - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合
- ~~**消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。**~~
- **共享内存（Shared Memory）**：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
  - 优点：无须复制，快捷，信息量大
  - 缺点：
    1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
    2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
- ~~**共享内存通信方式，如果多个进程同时修改同一个共享内存，很有可能就冲突了。为了防止多进程竞争共享资源而造成的数据错乱，所以需要保护机制，使得共享的资源在任意时刻只能被一个进程访问。**~~
- **信号量（Semaphore）**：一个计数器，可以用来控制多个线程对共享资源的访问
  - 优点：可以同步进程
  - 缺点：信号量有限
- ~~**前面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。**~~
- **信号（Signal）**：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
- ~~**前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。**~~
- **套接字（Socket）**：可用于不同计算机间的进程通信
  - 优点：
    1. 传输数据为字节级，传输数据可自定义，数据量小效率高
    2. 传输数据时间短，性能高
    3. 适合于客户端和服务器端之间信息实时交互
    4. 可以加密,数据安全性强
  - 缺点：需对传输的数据进行解析，转化成应用级的数据。

### 线程间通信

- **锁机制**：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
  - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
  - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
  - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- **信号量机制(Semaphore)**
  - 无名线程信号量
  - 命名线程信号量
- **信号机制(Signal)**：类似进程间的信号处理
- **屏障（barrier）**：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制

---

### Linux内核同步

**原因**

在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实像多进程多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。

**同步方式**

- **原子操作**
  - 所谓原子操作，就是该操作绝不会在执行完毕前被任何其他任务或事件打断，也就说，它的最小的执行单位，不可能有比它更小的执行单位，因此这里的原子实际是使用了物理学里的物质微粒的概念。
  - 原子操作需要硬件的支持，因此是架构相关的，其API和原子类型的定义都定义在内核源码树的include/asm/atomic.h文件中，它们都使用汇编语言实现，因为C语言并不能实现这样的操作。
  - 原子操作主要用于实现资源计数，很多引用计数(refcnt)就是通过原子操作实现的。
- **信号量（semaphore）**
  - Linux内核的信号量在概念和原理上与用户态的System V的IPC机制信号量是一样的，但是它绝不可能在内核之外使用，因此它与System V的IPC机制信号量毫不相干。
  - 信号量在创建时需要设置一个初始值，表示同时可以有几个任务可以访问该信号量保护的共享资源，初始值为1就变成互斥锁（Mutex），即同时只能有一个任务可以访问信号量保护的共享资源。一个任务要想访问共享资源，首先必须得到信号量，获取信号量的操作将把信号量的值减1，若当前信号量的值为负数，表明无法获得信号量，该任务必须挂起在该信号量的等待队列等待该信号量可用；若当前信号量的值为非负数，表示可以获得信号量，因而可以立刻访问被该信号量保护的共享资源。当任务访问完被信号量保护的共享资源后，必须释放信号量，释放信号量通过把信号量的值加1实现，如果信号量的值为非正数，表明有任务等待当前信号量，因此它也唤醒所有等待该信号量的任务。
- 读写信号量（rw_semaphore）
  - 读写信号量对访问者进行了细分，或者为读者，或者为写者，读者在保持读写信号量期间只能对该读写信号量保护的共享资源进行读访问，如果一个任务除了需要读，可能还需要写，那么它必须被归类为写者，它在对共享资源访问之前必须先获得写者身份，写者在发现自己不需要写访问的情况下可以降级为读者。读写信号量同时拥有的读者数不受限制，也就说可以有任意多个读者同时拥有一个读写信号量。如果一个读写信号量当前没有被写者拥有并且也没有写者等待读者释放信号量，那么任何读者都可以成功获得该读写信号量；否则，读者必须被挂起直到写者释放该信号量。如果一个读写信号量当前没有被读者或写者拥有并且也没有写者等待该信号量，那么一个写者可以成功获得该读写信号量，否则写者将被挂起，直到没有任何访问者。因此，写者是排他性的，独占性的。
- **自旋锁（spinlock）**
  - 自旋锁与互斥锁有点类似，只是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，"自旋"一词就是因此而得名。由于自旋锁使用者一般保持锁时间非常短，因此选择自旋而不是睡眠是非常必要的，自旋锁的效率远高于互斥锁。
  - 信号量和读写信号量适合于保持时间较长的情况，它们会导致调用者睡眠，因此只能在进程上下文使用（_trylock的变种能够在中断上下文使用），而自旋锁适合于保持时间非常短的情况，它可以在任何上下文使用。如果被保护的共享资源只在进程上下文访问，使用信号量保护该共享资源非常合适，如果对共巷资源的访问时间非常短，自旋锁也可以。但是如果被保护的共享资源需要在中断上下文访问（包括底半部即中断处理句柄和顶半部即软中断），就必须使用自旋锁。
  - 自旋锁保持期间是抢占失效的，而信号量和读写信号量保持期间是可以被抢占的。自旋锁只有在内核可抢占或SMP的情况下才真正需要，在单CPU且不可抢占的内核下，自旋锁的所有操作都是空操作。
  - 跟互斥锁一样，一个执行单元要想访问被自旋锁保护的共享资源，必须先得到锁，在访问完共享资源后，必须释放锁。如果在获取自旋锁时，没有任何执行单元保持该锁，那么将立即得到锁；如果在获取自旋锁时锁已经有保持者，那么获取锁操作将自旋在那里，直到该自旋锁的保持者释放了锁。
  - 无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。
- 大内核锁（BKL，Big Kernel Lock）
  - 大内核锁本质上也是自旋锁，但是它又不同于自旋锁，自旋锁是不可以递归获得锁的，因为那样会导致死锁。但大内核锁可以递归获得锁。大内核锁用于保护整个内核，而自旋锁用于保护非常特定的某一共享资源。
  - 需要特别指出，整个内核只有一个大内核锁，其实不难理解，内核只有一个，而大内核锁是保护整个内核的，当然有且只有一个就足够了。
  - 还需要特别指出的是，大内核锁是历史遗留，内核中用的非常少，一般保持该锁的时间较长，因此不提倡使用它。从2.6.11内核起，大内核锁可以通过配置内核使其变得可抢占（自旋锁是不可抢占的），这时它实质上是一个互斥锁，使用信号量实现。
- 读写锁（rwlock）
  - 读写锁实际是一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。这种锁相对于自旋锁而言，能提高并发性，因为在多处理器系统中，它允许同时有多个读者来访问共享资源，最大可能的读者数为实际的逻辑CPU数。写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者。
  - 在读写锁保持期间也是抢占失效的。
  - 如果读写锁当前没有读者，也没有写者，那么写者可以立刻获得读写锁，否则它必须自旋在那里，直到没有任何写者或读者。如果读写锁没有写者，那么读者可以立即获得该读写锁，否则读者必须自旋在那里，直到写者释放该读写锁。
- 大读者锁（brlock-Big Reader Lock）
  - 大读者锁是读写锁的高性能版，读者可以非常快地获得锁，但写者获得锁的开销比较大。大读者锁只存在于2.4内核中，在2.6中已经没有这种锁（提醒读者特别注意）。它们的使用与读写锁的使用类似，只是所有的大读者锁都是事先已经定义好的。这种锁适合于读多写少的情况，它在这种情况下远好于读写锁。
  - 大读者锁的实现机制是：每一个大读者锁在所有CPU上都有一个本地读者写者锁，一个读者仅需要获得本地CPU的读者锁，而写者必须获得所有CPU上的锁。
- **读-拷贝修改(RCU，Read-Copy Update)**
  - RCU(Read-Copy Update)，顾名思义就是读-拷贝修改，它是基于其原理命名的。对于被RCU保护的共享数据结构，读者不需要获得任何锁就可以访问它，但写者在访问它时首先拷贝一个副本，然后对副本进行修改，最后使用一个回调（callback）机制在适当的时机把指向原来数据的指针重新指向新的被修改的数据。这个时机就是所有引用该数据的CPU都退出对共享数据的操作。
  - RCU也是读写锁的高性能版本，但是它比大读者锁具有更好的扩展性和性能。 RCU既允许多个读者同时访问被保护的数据，又允许多个读者和多个写者同时访问被保护的数据（注意：是否可以有多个写者并行访问取决于写者之间使用的同步机制），读者没有任何同步开销，而写者的同步开销则取决于使用的写者间同步机制。但RCU不能替代读写锁，因为如果写比较多时，对读者的性能提高不能弥补写者导致的损失。
- 顺序锁（seqlock）
  - 顺序锁也是对读写锁的一种优化，对于顺序锁，读者绝不会被写者阻塞，也就说，读者可以在写者对被顺序锁保护的共享资源进行写操作时仍然可以继续读，而不必等待写者完成写操作，写者也不需要等待所有读者完成读操作才去进行写操作。但是，写者与写者之间仍然是互斥的，即如果有写者在进行写操作，其他写者必须自旋在那里，直到写者释放了顺序锁。
  - 这种锁有一个限制，它必须要求被保护的共享资源不含有指针，因为写者可能使得指针失效，但读者如果正要访问该指针，将导致OOPs。
  - 如果读者在读操作期间，写者已经发生了写操作，那么，读者必须重新读取数据，以便确保得到的数据是完整的。
  - 这种锁对于读写同时进行的概率比较小的情况，性能是非常好的，而且它允许读写同时进行，因而更大地提高了并发性。

---

### <span id = "netio">网络I/O模型</span>

在描述这块内容的诸多书籍中，很多都只说笼统的概念，我们将问题具体化，暂时只考虑服务器端的网络I/O情形。我们假定目前的情形是服务器已经在监听用户请求，建立连接后服务器调用read()函数等待读取用户发送过来的数据流，之后将接收到的数据打印出来。

所以服务器端简单是这样的流程：建立连接 -> 监听请求 -> 等待用户数据 -> 打印数据。我们总结网络通信中的等待：

- 建立连接时等待对方的ACK包（TCP）。

- 等待客户端请求（HTTP）。

- 输入等待：服务器用户数据到达内核缓冲区（read函数等待）。

- 输出等待：用户端等待缓冲区有足够空间可以输入（write函数等待）。

另外为了能够解释清楚网络I/O模型，还需要了解一些基础。对服务器而言，打印出用户输入的字符串（printf函数）和从网络中获取数据（read函数）需要单独来看。服务器首先accept用户连接请求后，然后调用read函数等待数据，这里的read函数是系统调用，运行于内核态，使用的也是内核地址空间，并且从网络中取得的数据需要先写入到内核缓冲区。当read系统调用获取到数据后将这些数据再复制到用户地址空间的用户缓冲区中，之后返回到用户态执行printf函数打印字符串。我们需要明确两点：

- read执行在内核态且数据流先读入内核缓冲区；printf运行于用户态，打印的数据会先从内核缓冲区复制到进程的用户缓冲区，之后打印出来。

- printf函数一定是在read函数已经准备好数据之后才能执行，但read函数作为I/O操作通常需要等待而触发阻塞。调用read函数的是服务器进程，一旦被read调用阻塞，整个服务器在获取到用户数据前都不能接受任何其他用户的请求（单进程/线程）。

有了上面的基础，我们就可以介绍下面四种网路I/O模型。

**阻塞式**

 - 阻塞表示一旦调用I/O函数必须等整个I/O完成才返回。正如上面提到的那种情形，当服务器调用了read函数之后，如果不是立即接收到数据，服务器进程会被阻塞，之后一直在等待用户数据到达，用户数据到达后首先会写进内核缓冲区，之后内核缓冲区数据复制到用户进程（服务器进程）缓冲区。完成了上述所有的工作后，才会把执行权限返回给用户（从内核态 -> 用户态）。

- 很显然，阻塞式I/O的效率实在太低，如果用户输入数据迟迟不到的话，整个服务器就会一直被阻塞（单进程/线程）。为了不影响服务器接收其他进程的连接，我们可以考虑多进程模型，这样当服务器建立连接后为连接的用户创建新线程，新线程即使是使用阻塞式I/O也仅仅是这一个线程被阻塞，不会影响服务器等待接收新的连接。

- 多线程模型下，主线程等待用户请求，用户有请求到达时创建新线程。新线程负责具体的工作，即使是因为调用了read函数被阻塞也不会影响服务器。我们还可以进一步优化创建连接池和线程池以减小频繁调用I/O接口的开销。但新问题随之产生，每个新线程或者进程（加入使用对进程模型）都会占用大量系统资源，除此之外过多的线程和进程在调度方面开销也会大很对，所以这种模型并不适合大并发量。

**非阻塞I/O**

- 阻塞和非阻塞最大的区别在于调用I/O系统调用后，是等整个I/O过程完成再把操作权限返回给用户还是会立即返回。

- 可以使用以下语句将句柄fd设置为非阻塞I/O：fcntl(fd, F_SETFL, O_NONBLOCK);

- 非阻塞I/O在调用后会立即返回，用户进程对返回的返回值判断以区分是否完成了I/O。如果返回大于0表示完成了数据读取，返回值即读取的字节数；返回0表示连接已经正常断开；返回-1表示错误，接下来用户进程会不停地询问kernel是否准备完毕。

- 非阻塞I/O虽然不再会完全阻塞用户进程，但实际上由于用户进程需要不停地询问kernel是否准备完数据，所以整体效率依旧非常低，不适合做并发。

**I/O多路复用（事件驱动模型）**

前面已经论述了多进程、多进程模型会因为开销巨大和调度困难而导致并不能承受高并发量。但不适用这种模型的话，无论是阻塞还是非阻塞方式都会导致整个服务器停滞。

所以对于大并发量，我们需要一种代理模型可以帮助我们集中去管理所有的socket连接，一旦某个socket数据到达了就执行其对应的用户进程，I/O多路复用就是这么一种模型。Linux下I/O多路复用的系统调用有select，poll和epoll，但从本质上来讲他们都是同步I/O范畴。

1. select

    - 相关接口：

        ```cpp
        int select (int maxfd, fd_set *readfds, fd_set *writefds, fd_set *errorfds, struct timeval *timeout);
        FD_ZERO(int fd, fd_set* fds)   	//清空集合
        FD_SET(int fd, fd_set* fds)    	//将给定的描述符加入集合
        FD_ISSET(int fd, fd_set* fds)   //将给定的描述符从文件中删除
        FD_CLR(int fd, fd_set* fds)    	//判断指定描述符是否在集合中
        ```

    - 参数：
        maxfd：当前最大文件描述符的值+1（≠ MAX_CONN）。
        
        readfds：指向读文件队列集合（fd_set）的指针。
        
        writefds：同上，指向读集合的指针。
        
        writefds：同上，指向错误集合的指针。
        
        timeout：指向timeval结构指针，用于设置超时。

    - 其他：

        判断和操作对象为set_fd集合，集合大小为单个进程可打开的最大文件数1024或2048（可重新编译内核修改但不建议）。

2. poll
    - 相关接口：

        ```cpp
        int poll(struct pollfd *fds, unsigned int nfds, int timeout);
        ```

    - 结构体定义：
        
        ```cpp
        struct pollfd{
            int fd;    		// 文件描述符
            short events;   // 等到的事件
        short revents;  // 实际发生的事件
        }
        ```
        
    - 参数：
        fds：指向pollfd结构体数组的指针。
        
        nfds：pollfd数组当前已被使用的最大下标。
        
        timeout：等待毫秒数。

    - 其他：

        判断和操作对象是元素为pollfd类型的数组，数组大小自己设定，即为最大连接数。

3. epoll
   
    - 相关接口：
        
        ```cpp
        int epoll_create(int size);    // 创建epoll句柄
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);   // 事件注册函数
        int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
        ```
        
    - 结构体定义：
        
        ```cpp
        struct epoll_event{
            __uint32_t events;
            epoll_data_t data;
        };
        typedef union epoll_data{
        void *ptr;
            int fd;
            __uint32_t u32;
        __uint64_t u64;
        }epoll_data_t;
        ```
        
    - 参数：
      size：用来告诉内核要监听的数目。
        
        epfd：epoll函数的返回值。
        
        op：表示动作（EPOLL_CTL_ADD/EPOLL_CTL_FD/EPOLL_CTL_DEL）。
        
        fd：需要监听的fd。
        
    events：指向epoll_event的指针，该结构记录监听的事件。
       
       maxevents：告诉内核events的大小。
       
       timeout：超时时间（ms为单位，0表示立即返回，-1将不确定）。
   
4. select、poll和epoll区别
    - 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，每次调用都需要将整个集合拷贝到内核态；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要执行一个系统调用。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。
    - select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
    - select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，它们会采用遍历的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，会自动触发epoll回调函数通知epoll文件描述符，然后内核将这些就绪的文件描述符放到之前提到的ready list中等待epoll_wait调用后被处理。
    - select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。

    综上，当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

**异步I/O模型**

- 上面三种I/O方式均属于同步I/O。

- 从阻塞式I/O到非阻塞I/O，我们已经做到了调用I/O请求后立即返回，但不停轮询的操作效率又很低，如果能够既像非阻塞I/O能够立即返回又能不一直轮询的话会更符合我们的预期。

- 之所以用户进程会不停轮询就是因为在数据准备完毕后内核不会回调用户进程，只能通过用户进程一次又一次轮询来查询I/O结果。如果内核能够在完成I/O后通过消息告知用户进程来处理已经得到的数据自然是最好的，异步I/O就是这么回事。

- 异步I/O就是当用户进程发起I/O请求后立即返回，直到内核发送一个信号，告知进程I/O已完成，在整个过程中，都没有进程被阻塞。看上去异步I/O和非阻塞I/O的区别在于：判断数据是否准备完毕的任务从用户进程本身被委托给内核来完成。这里所谓的异步只是操作系统提供的一直机制罢了。

### 死锁

**原因**

- 系统资源不足
- 资源分配不当
- 进程运行推进顺序不合适

**产生条件**

多个并发进程因争夺系统资源而产生相互等待的现象。

- **互斥条件**：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；
- **请求和保持条件**：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源
- **不可剥夺条件**：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放
- **环路等待条件**：进程发生死锁后，必然存在一个进程-资源之间的环形链 ，环路中每个进程都在等待下一个进程所占有的资源

**预防**

- **破坏请求和等待条件。** 所有的进程在开始运行前，必须一次性地申请其在整个运行过程中所需要的全部资源
- **破坏不可抢占条件。** 当进程新的资源未得到满足时，释放已占有的资源
- **破坏环路等待条件。** 系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反
- 有序资源分配法
- 银行家算法

**检测**

- 首先为每个进程和每个资源指定一个唯一的号码； 然后建立资源分配表和进程等待表

- GDB调试

**恢复**

- **抢占恢复。** 从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态

- **回滚恢复。** 周期性地检查进程的状态（包括请求的资源），将其写入一个文件，当发生死锁，回滚到之前的某个时间点

- **杀死进程恢复。** 终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。

### 进程中断

**中断：**所谓中断就是指CPU在正常执行程序的时候，由于内部/外部事件的出发、或由程序预先设定而引起CPU暂时中止当前正在执行的程序，保存被执行程序相关信息到栈中，转而去执行为内部/外部事件、或由程序预先设定事件的中断服务子程序，待执行完中断服务子程序后，CPU再获取被保存在栈中被中断的程序的信息，继续执行被中断的程序，这一过程叫做中断。

**请求中断→响应中断→关闭中断→保留断点→中断源识别→保护现场→中断服务子程序→恢复现场→中断返回。**

**中断处理过程:**

**（1）某一中断源向CPU发起中断请求**，对于外部中断CPU在当前指令最后一个时钟周期查询中断请求信号的有效性，在系统开中断的情况下，CPU向中断源回送中断应答信号，系统进入中断响应周期（CPU对系统内部中断源提出的中断请求必须响应，而且自动取得中断服务子程序的入口地址，执行中断服务子程序）；

**（2）CPU响应中断后**，将状态标志寄存器压入堆栈保护；

**（3）**再将其中的中断标志位清除从而关闭中断；

**（4）**CPU将当前CS（代码段地址）和IP（将要执行的下一条地址）压入堆栈**保护断点**；

**（5）CPU确定提出请求的中断源**，获得**中断向量号**，在对应的中断向量表获得中断入口地址，装入CS和IP中；

**（6）**将断点处各寄存器的内容压入堆栈**保护现场**；

**（7）**此时程序跳转至**中断服务子程序执行**；

**（8）**中断处理完毕，将堆栈各寄存器内容弹栈，**恢复断点处各寄存器的值**；

**（9）**在中断服务子程序最后安排一条**返回指令**，执行该指令将堆栈中CS和IP的值弹出，恢复主程序断点处地址值，同时恢复标志寄存器的内容。程序转至被中断的程序继续执行。

### 页面置换算法

当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。

当前操作系统最常采用的缺页置换算法如下：

![image-20200826174807919](C:\Users\gxl\AppData\Roaming\Typora\typora-user-images\image-20200826174807919.png)

- 先进先出（FIFO）算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

- 最近最少使用（LRU）算法：置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

- 最近最少使用（LFU）算法：如果一个数据在最近一段时间很少被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最小频率访问的数据最先被淘汰。

### 进程调度算法

**批处理系统**

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

- 先来先服务 first-come first-serverd（FCFS）
  非抢占式的调度算法，按照请求的顺序进行调度。
  有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

- 短作业优先 shortest job first（SJF）
  非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
  长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

- 最短剩余时间优先 shortest remaining time next（SRTN）
  最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。
  当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**交互式系统**

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

- 时间片轮转
  将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
  当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
- 优先级调度
  为每个进程分配一个优先级，按优先级进行调度。
  为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
- 多级反馈队列
  一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
  多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
  每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。
  可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

**实时系统**

- 实时系统要求一个请求在一个确定时间内得到响应。
- 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

### 物理地址、虚拟地址

首先将给定逻辑地址（其实是段内偏移量），CPU利用其段式内存管理单元，先将逻辑地址转换成线性地址，再利用其页式内存管理单元，转换为最终物理地址。

线性地址：是CPU所能寻址的空间或者范围。
物理地址：是机器中实际的内存地址。换言之，是机器中的内存容量范围。
逻辑地址：是对程序而言的。一般以Seg:Offset来表示（程序员自己看到的地址）

因此，最准确的关系是：逻辑地址通过线性地址完成物理地址的映射，线性地址完全是充当"桥"的作用。

**虚拟内存**

1. 每个进程的4G内存空间只是虚拟内存空间，每次访问内存空间的某个地址，都需要把地址翻译为实际物理内地址

2. 所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。

3. 进程要知道哪些内存地址上的数据在物理内存上，哪些不在，还有在物理内存上的哪里，需要用页表来记录

4. 页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）

5. 当进程访问某个虚拟地址，去看页表，如果发现对应的数据不在物理内存中，则缺页异常

6. 缺页异常的处理过程，就是把进程需要的数据从磁盘上拷贝到物理内存中，如果内存已经满了，没有空地方了，那就找一个页覆盖，当然如果被覆盖的页曾经被修改过，需要将此页写回磁盘

事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。

还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

![image-20200828150214161](C:\Users\gxl\AppData\Roaming\Typora\typora-user-images\image-20200828150214161.png)

可以认为虚拟空间都被映射到了磁盘空间中（事实上也是按需要映射到磁盘空间上，通过mmap），并且由页表记录映射位置，当访问到某个地址的时候，通过页表中的有效位，可以得知此数据是否在内存中，如果不是，则通过缺页异常，将磁盘对应的数据拷贝到内存中，如果没有空闲内存，则选择牺牲页面，替换其他页面。

mmap是用来建立从虚拟空间到磁盘空间的映射的，可以将一个虚拟空间地址映射到一个磁盘文件上，当不设置这个地址时，则由系统自动设置，函数返回对应的内存地址（虚拟地址），当访问这个地址的时候，就需要把磁盘上的内容拷贝到内存了，然后就可以读或者写，最后通过manmap可以将内存上的数据换回到磁盘，也就是解除虚拟空间和内存空间的映射，这也是一种读写磁盘文件的方法，也是一种进程共享数据的方法 **共享内存**

### 进程有哪几种状态？

**创建状态**：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态

**就绪状态**：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行

**执行状态**：进程处于就绪状态被调度后，进程进入执行状态

**阻塞状态**：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用

**终止状态**：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行

![这里写图片描述](https://img-blog.csdn.net/20160906192211991)

### 用户态和内核态

通过**系统调用**将Linux整个体系分为用户态和内核态（或者说内核空间和用户空间）。

内核态从本质上说就是所说的内核，它是一种**特殊的软件程序**，特殊在哪儿呢？**控制计算机的硬件资源，例如协调CPU资源，分配内存资源，并且提供稳定的环境供应用程序运行**。

用户态就是提供应用程序运行的空间，为了使应用程序访问到内核管理的资源例如CPU，内存，I/O。内核必须提供一组通用的访问接口，这些接口就叫**系统调用。**

![img](https://picb.zhimg.com/80/v2-d3723a14f07a42c7e016ae9bc38eddef_720w.jpg)

- **系统调用**时操作系统的最小功能单位。根据不同的应用场景，不同的Linux发行版本提供的系统调用数量也不尽相同，大致在240-350之间。这些系统调用组成了用户态跟内核态交互的基本接口，**例如：用户态想要申请一块20K大小的动态内存，就需要brk系统调用，将数据段指针向下偏移，如果用户态多处申请20K动态内存，同时又释放呢？这个内存的管理就变得非常的复杂。**

- **库函数**就是屏蔽这些复杂的底层实现细节，减轻程序员的负担，从而更加关注上层的逻辑实现。它对系统调用进行封装，提供简单的基本接口给用户，这样增强了程序的灵活性，当然对于简单的接口，也可以直接使用系统调用访问资源，例如：**open（），write（），read（）**等等。库函数根据不同的标准也有不同的版本，例如：**glibc库，posix库**等。

- **shell**顾名思义，就是外壳的意思。就好像把内核包裹起来的外壳。它是一种特殊的应用程序，俗称命令行。为了方便用户和系统交互，一般一个shell对应一个终端，呈现给用户交互窗口。当然shell也是编程的，它有标准的shell语法，符合其语法的文本叫**shell脚本**。很多人都会用shell脚本实现一些常用的功能，可以提高工作效率。

从用户态到内核态切换可以通过三种方式：

1. 系统调用，这个上面已经讲解过了，在我公众号之前的文章也有讲解过。其实系统调用本身就是中断，但是软件中断，跟硬中断不同。
2. 异常：如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常。
3. 外设中断：当外设完成用户的请求时，会向CPU发送中断信号。

### 生产者消费者模型

```cpp
semaphore mutex=1;	//临界区互斥信号量
semaphore empty=n;	//空闲缓冲区
semaphore full=0;	//缓冲区初始化为0

preoducer(){		//生产者进程
    while(1){
        produce an item in nextp;	//生产数据
        P(empty);					//获取空缓冲区单元
        P(mutex);					//进入临界区
        add nextp to bugger;		//将数据放入缓冲区
        V(mutex);					//离开临界区，释放互斥信号量
        V(full);					//满缓冲区数加1
    }
}

consumer(){			//消费者进程
    while(1){
        P(full);					//获取满缓冲区单元
        P(mutex);					//进入临界区
        remove an item from buffer;	//从缓冲区中取出数据
        V(mutex);					//离开临界区，释放互斥信号量
        V(empty);					//空缓冲区数加1
        consume the item;			//消费数据
    }
}
```

### 线程安全

**互斥锁**

在多任务操作系统中，同时运行的多个任务可能都需要使用同一种资源。在线程里有互斥锁，互斥锁是一种简单的加锁的方法来控制对共享资源的访问，互斥锁只有两种状态，即**上锁( lock )和解锁( unlock )**。

**原子性**：把一个互斥量锁定为一个原子操作，这意味着操作系统（或pthread函数库）保证了如果一个线程锁定了一个互斥量，没有其他线程在同一时间可以成功锁定这个互斥量；

**唯一性**：如果一个线程锁定了一个互斥量，在它解除锁定之前，没有其他线程可以锁定这个互斥量；

**非繁忙等待**：如果一个线程已经锁定了一个互斥量，第二个线程又试图去锁定这个互斥量，则第二个线程将被挂起（不占用任何cpu资源），直到第一个线程解除对这个互斥量的锁定为止，第二个线程则被唤醒并继续执行，同时锁定这个互斥量。

**条件变量**

与互斥锁不同，条件变量是用来等待而不是用来上锁的。条件变量用来自动阻塞一个线程，直 到某特殊情况发生为止。通常条件变量**和互斥锁同时使用**。条件变量使我们可以睡眠等待某种条件出现。

条件的检测是在互斥锁的保护下进行的。**线程在改变条件状态之前必须首先锁住互斥量**。如果一个条件为假，一个线程自动阻塞，并释放等待状态改变的互斥锁。如果另一个线程改变了条件，它发信号给关联的条件变量，唤醒一个或多个等待它的线程，重新获得互斥锁，重新评价条件。如果两进程共享可读写的内存，条件变量 可以被用来实现这两进程间的线程同步。

**信号量**

信号量和互斥锁的区别：互斥锁只允许一个线程进入临界区，而信号量允许多个线程进入临界区，

信号量广泛用于进程或线程间的同步和互斥，信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问。编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值大于 0 时，则可以访问，否则将阻塞。PV 原语是对信号量的操作，一次 P 操作使信号量减１，一次 V 操作使信号量加１。

### Linux4G布局

![image-20200826153557192](C:\Users\gxl\AppData\Roaming\Typora\typora-user-images\image-20200826153557192.png)

### 浏览器输入请求，服务器怎么处理

- 用户在Web浏览器中键入“IP地址:端口号”，浏览器直接根据IP地址向对应的服务器发送一个HTTP请求（这个过程中，有TCP的三次握手，然后HTTP协议生成HTTP请求报文，通过TCP/IP等协议发送到目标服务器上）
- Web服务器端通过`socket`监听指定的`port`上来自用户的请求，监听到的新客户连接会被放入监听队列，同时需要告诉服务器有连接来了需要`accept`，并分配一个逻辑单元来处理这个用户请求
- 将`listenfd`上到达的`connection`通过 `accept()`接收，并返回一个新的socket文件描述符`connfd`用于和用户通信，并对用户请求返回响应，同时将这个`connfd`注册到内核事件表中，等用户发来请求报文
- 通过`epoll_wait`发现这个`connfd`上有可读事件了（`EPOLLIN`），主线程就将这个HTTP的请求报文读进这个连接套接字的读缓存中`users[sockfd].read()`，然后将该任务对象（指针）插入线程池的请求队列中
- 然后服务器端就会解析这个HTTP请求，然后处理对应的GET/POST请求，然后返回给一个HTML页面